<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Manhole | Amarnath Murugan</title> <meta name="author" content="Amarnath Murugan"/> <meta name="description" content="Award-winning real-time animated short film"/> <meta name="keywords" content="amarnath, murugan, graphics programming, gpu, researcher, research, shaders, hci, unity, unreal, game dev"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸŒŒ</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://amarnathmurugan.github.io/projects/manhole/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">AmarnathÂ </span>Murugan</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item "><a class="nav-link" href="/projects/">Projects</a></li> <li class="nav-item "><a class="nav-link" href="/publications/">Publications</a></li> <li class="nav-item "><a class="nav-link" href="/assets/pdf/CV.pdf">CV</a></li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Manhole</h1> <p class="post-description">Award-winning real-time animated short film</p> </header> <article> <div class="row" style="text-align:center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/projects/manhole/manhole_poster.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>â€˜Manholeâ€™ is an animated short film that depicts the struggles of manual scavengers, a marginalized group in India who clean dangerous sewers and manholes with barely any protective equipment.</p> <p>We created the movie during Epic Gameâ€™s <a href="https://www.unrealengine.com/en-US/blog/watch-the-top-projects-from-the-shorts-india-program" target="_blank" rel="noopener noreferrer">Shorts India Program</a>, where top studios in the country competed to make a film in 3 months with funding and mocap studio access provided by Epic. Our team, however, was an odd one out. We were a group of independent artists who hadnâ€™t worked on a 3D film before. Despite this handicap, we emerged <strong>third</strong> in the competition, winning $15k. â€˜Manholeâ€™ was also one of the 72 films from over 1300 submissions screened at the prestigious <strong>Annecy Film Festival</strong>. <br></p> <div class="embed-container" style="text-align:center"> <iframe src="https://www.youtube.com/embed/NYyHxQjr3Z8" width="700" height="400" frameborder="0" allowfullscreen="true"> </iframe> </div> <div class="caption"> Manhole - Short Film Trailer </div> <p>As the filmâ€™s <strong>Technical Director</strong> and <strong>Producer</strong>, I tackled some interesting technical and logistical challenges to help create a short with a real-time workflow and distributed team, where almost all the members were using a game engine for the first time. <br><br></p> <h3 id="pre-production">Pre-Production</h3> <p>We started pre-production in 2020, intending to make a real-time VR film. The co-director, Abishek Verma â€” after winning a national award for his 2D animated film â€˜Machar Jholâ€™ â€” spent two years studying the plight of manual scavengers and pitched the project to our lab; due to our research experience in storytelling for VR. As we had no funding when the project started, all the core members volunteered their time to complete pre-production.</p> <p>To reduce the rendering time and have the experience running in VR, I worked with the directors to scope the screenplay and with the artists to decide the ideal level design, poly count, and texel density. We originally intended to have a toon-shaded look, and I wrote a custom shader in unity with the lighting pass implemented from scratch. This allowed me to expose parameters related to toon shading and implement cross-hatching in the shadows.</p> <div class="row" style="text-align:center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/projects/manhole/toon.gif" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Initial experiment with cross-hatched toon shader </div> <div class="row" style="text-align:center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/projects/manhole/toon1.gif" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Shading test with character in sewer </div> <p>I textured the dirt layer on the character and the manhole in the above image. Furthermore, the sludge layer was another custom shader driving the vertex offset of a plane with multiple alpha-blended PBR textures.</p> <p>A big challenge with making a VR film is that we canâ€™t have too many cuts. The animation for each character had to be one single clip, and we needed to see the pre-viz without needing a VR headset to provide easier feedback. Furthermore, the character positions had to be planned well to allow a good vantage point for the viewer to see all the action. The team first created a 2D animatic that shows the timing and position. Based on the 2D version, our animator created playblasts in Maya depicting the character movements and interactions.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/projects/manhole/animatic2d.gif" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/projects/manhole/animatic3d.gif" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> 2D &amp; 3D Animatic </div> <p><br></p> <h3 id="production">Production</h3> <p>With the pre-production completed, our team was actively seeking funding to start production in 2021. However, due to COVID, that proved to be difficult. We later found out about Epic Gameâ€™s Shorts India Program, but the participants had to be invited by the Epic team. Fortunately, I was an active member of the game development community in India and was an invited speaker at events conducted by the same team. I promptly contacted them and set up a call to pitch our project. Our pre-production work earned us an invite, with a week left before the competition began.</p> <p>The requirements of the program imposed new challenges. The submission had to be a non-VR film with a lesser runtime than the one indicated by our screenplay. Moreover, we switched game engines, and instead of toon-shading, we decided to go with PBR. We also created more custom 3D models and captured more motion and face data than other teams, which made production even more challenging.</p> <h5 id="enter-the-manhole">Enter the Manhole</h5> <p>The scenes where the protagonist is inside the sewer are crucial. It shows the conditions in which a manual scavenger works, and it is imperative for this part to be impactful. Two elements in the scene contribute to this. First, the sludge within the sewer must seem disgusting. Second, as the character interacts with the sludge, his skin must become grimier.</p> <p>I used <a href="https://www.unrealengine.com/marketplace/en-US/product/fluidninja-live" target="_blank" rel="noopener noreferrer">FluidNinja Live</a>, to get a realistic water surface thatâ€™s also interactive. Then changed the shading and physics parameters to make the sludge look right.</p> <video width="100%" preload="auto" muted="" autoplay="" loop="" class="img-fluid rounded z-depth-1"> <source src="/assets/img/projects/manhole/fluid.mp4" type="video/mp4"></source> </video> <div class="caption"> Initial fluid interaction test </div> <p>With the shading out of the way, I implemented buoyancy for the garbage floating on the waterâ€™s surface. FluidNinja exposes velocity and density buffers, which I saved in a render texture and sampled in a blueprint to have the garbage move correctly on the surface. Next, I added static junk on the sides, whose vertices are offset in Z based on the density buffer to make them rise and fall with the water.</p> <video width="100%" preload="auto" muted="" autoplay="" loop="" class="img-fluid rounded z-depth-1"> <source src="/assets/img/projects/manhole/fluidpenul.mp4" type="video/mp4"></source> </video> <div class="caption"> Fluid without reactive garbage </div> <video width="100%" preload="auto" muted="" autoplay="" loop="" class="img-fluid rounded z-depth-1"> <source src="/assets/img/projects/manhole/finalsludge.mp4" type="video/mp4"></source> </video> <div class="caption"> Fluid with garbage, as shown in the film </div> <p>The next part was shading the character after he interacted with the sludge. For wetness, I modified the metahuman skin shaderâ€™s specularity and roughness values based on a texture I painted in Quixel Mixer that marks the location of droplets. I also created another texture that demarcates the areas where water drips and combined it with an animated Perlin noise in the shader. I then use this to modify the normals and specular values to render animated dripping water on skin. My approach was based on a <a href="https://www.youtube.com/watch?v=tvBIqPHaExQ&amp;t=1112s" target="_blank" rel="noopener noreferrer">technique</a> from The Last of Us 2. Next, I added a dirt layer on the skin. I painted two textures that act as masks for the dirt and used them to modify the base albedo. Before changing the base color, I used a parameter that interpolates between clear skin and the two textures to gradually increase the characterâ€™s griminess.</p> <video width="100%" preload="auto" muted="" autoplay="" loop="" class="img-fluid rounded z-depth-1"> <source src="/assets/img/projects/manhole/watershader.mp4" type="video/mp4"></source> </video> <div class="caption"> Water dripping test </div> <video width="100%" preload="auto" muted="" autoplay="" loop="" class="img-fluid rounded z-depth-1"> <source src="/assets/img/projects/manhole/finalskin.mp4" type="video/mp4"></source> </video> <div class="caption"> End result of grime shader </div> <h5 id="animation">Animation</h5> <p>On the day of mocap, we had three hours to capture close to fifty shots. The studio had just one actor, while some of our shots required three characters to interact simultaneously. To further complicate matters, we had an underwater scene, and the actor had to be suspended on a crane at the end of the session. Managing all this through zoom was incredibly challenging. We had to prioritize shots on the spot and art direct only the important ones.</p> <video width="100%" preload="auto" muted="" autoplay="" loop="" class="img-fluid rounded z-depth-1"> <source src="/assets/img/projects/manhole/mocap.mp4" type="video/mp4"></source> </video> <div class="caption"> Mocap session </div> <p>We received the mocap data less than a month before the deadline, which was noisier than expected. Unfortunately, we didnâ€™t have an animator onboarded by then. I spent the next three weeks trying to recruit animators. Most freelancers worked full-time with our competitors, making the process more difficult. When I finally onboarded an artist, we had issues with Unreal-Maya roundtripping for metahumans that precluded them from contributing. Fortunately, I negotiated a deal with <a href="https://www.appleartsstudios.com/" target="_blank" rel="noopener noreferrer">Apple Arts Studio</a>, who offered to clean up the raw mocap data at a much lower price, as they sympathized with the cause central to our project. <br><br></p> <div class="row" style="text-align:center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/projects/manhole/mocapjitter.gif" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/projects/manhole/mocapclean.gif" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> [Left] Original Data [Right] Cleaned Mocap data </div> <p>I had to solve two more issues with the cleaned-up raw data in hand. First, the data had to be retargeted to our metahuman character. We had almost an hour of mocap data with each clip saved at 30 fps, so the time it took to retarget a single clip was very high due to the number of keyframes. I solved this by writing an editor script that automated retargeting for all the imported clips. Second, the differences in the dimensions of our character and the actor introduced self-penetrations after retargeting. Additionally, recording three characters with one actor meant the gaze directions and hand positions were wrong when interacting. After considering the time we had left, we figured the best approach would be to use Unrealâ€™s metahuman control rig and do this pass of the cleanup within the engine. One of the design students from our lab was able to quickly pick up unreal and make these modifications.</p> <p>The next part was facial capture. We used Unrealâ€™s Live Link Face app on an iPhone and attached the device to a makeshift mocap helmet created using bamboo, a selfie stick, and a bicycle helmet. We also had to do further cleanup on this data, which considerably increased the person-hours needed to complete the film.</p> <video width="100%" preload="auto" muted="" autoplay="" loop="" class="img-fluid rounded z-depth-1"> <source src="/assets/img/projects/manhole/facecap.mp4" type="video/mp4"></source> </video> <div class="caption"> Face Capture session </div> <p>Apart from character animation, we had a scene that needed a rope to be animated. I used Unrealâ€™s Cable component to create a physics-based rope and set up hidden colliders in the scene to art direct the deformations. Furthermore, the rope had a bucket attached at the end, so that model was set as a constraint, and I keyframed its transform to get the result we wanted.</p> <h5 id="environment-assets">Environment Assets</h5> <p>The story occurs in a busy fictional street in Delhi, with the midday heat beating down on the protagonists. We onboarded <a href="https://deckor.co/" target="_blank" rel="noopener noreferrer">Deckor</a>, an Architecture Visualization company, to handle the asset creation. Their artists went to the streets of Delhi and collected tons of references to create the assets used in the film. I set the expected poly count and texture size for the assets based on their proximity to the virtual cameras and provided feedback on increasing their realism. After the artists completed level building, I did one more pass of level design to meet the artistic requirements set by the directors.</p> <video width="100%" preload="auto" muted="" autoplay="" loop="" class="img-fluid rounded z-depth-1"> <source src="/assets/img/projects/manhole/lighting2.mp4" type="video/mp4"></source> </video> <div class="caption"> Street assets render </div> </article> </div> </div> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>